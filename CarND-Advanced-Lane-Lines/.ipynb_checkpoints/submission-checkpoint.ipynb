{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "The images for camera calibration are stored in the folder called `camera_cal`.  The images in `test_images` are for testing your pipeline on single frames.  If you want to extract more test images from the videos, you can simply use an image writing method like `cv2.imwrite()`, i.e., you can read the video in frame by frame as usual, and for frames you want to save for later you can write to an image file.  \n",
    "\n",
    "To help the reviewer examine your work, please save examples of the output from each stage of your pipeline in the folder called `ouput_images`, and include a description in your writeup for the project of what each image shows.    The video called `project_video.mp4` is the video your pipeline should work well on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all the imports here\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calibrate camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to calibrate the camera using calibration images provided\n",
    "Also draw out the output of finding the chess board corners\n",
    "input\n",
    "images: list of images for calibration\n",
    "nx, ny: number of crossed dots in x and y direction\n",
    "output\n",
    "objpoints, imgpoints: coordinate of the crossed dots in 3d and in images space\n",
    "(see udacity course for explanation)\n",
    "\"\"\"\n",
    "def calibrate_camera(images, nx=9, ny=6):\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    objp = np.zeros((nx * ny, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    for i, fname in enumerate(images):\n",
    "        img = mpimg.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        # If found, draw corners, and add object and image points\n",
    "        if ret == True:\n",
    "            # Draw and display the corners\n",
    "            f, _ = plt.subplots(1, 1)\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "            cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            plt.imshow(img)\n",
    "            plt.savefig('./output_images/calibrate_chessboard%s.jpg' % str(i))\n",
    "    return objpoints, imgpoints\n",
    "\n",
    "objpoints, imgpoints= calibrate_camera(glob.glob('./camera_cal/calibration*.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function that takes an image, object points, and image points\n",
    "performs the camera calibration, image distortion correction and \n",
    "returns the undistorted image\n",
    "\"\"\" \n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[:2], None, None)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst\n",
    "\n",
    "\"\"\"\n",
    "helper function to plot out the undistored images\n",
    "\"\"\"\n",
    "def test_undistort(images):\n",
    "    for i, fname in enumerate(images):\n",
    "        img = mpimg.imread(fname)\n",
    "        undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original Image', fontsize=50)\n",
    "        ax2.imshow(undistorted)\n",
    "        ax2.set_title('Undistorted Image', fontsize=50)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.savefig('./output_images/test_undistort%s.jpg'%str(i))\n",
    "\n",
    "test_undistort(glob.glob('./test_images/test*.jpg') +\\\n",
    "               glob.glob('/test_images/straight_lines*.jpg') +\\\n",
    "               glob.glob('./camera_cal/calibration*.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Color and gradient threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# color filter based on the yellow and white lane color\n",
    "# this is inspired by the reviewer\n",
    "def select_yellow(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    lower = np.array([20,60,60])\n",
    "    upper = np.array([38,174, 250])\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    return mask\n",
    "\n",
    "def select_white(image):\n",
    "    lower = np.array([202,202,202])\n",
    "    upper = np.array([255,255,255])\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def select_white_yellow(image):\n",
    "    mask_yellow = select_yellow(image)\n",
    "    mask_white = select_white(image)\n",
    "    mask = np.zeros_like(mask_white)\n",
    "    mask[(mask_white>0) | (mask_yellow>0)] = 1\n",
    "    color_binary = np.dstack(( np.zeros_like(mask), mask_yellow, mask_white))\n",
    "    return color_binary, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to perform color and gradient (along x) thresholding\n",
    "input\n",
    "img: input image matrix\n",
    "output\n",
    "color binary: image matrix contains contribution from color and gradient thresholding\n",
    "combined binary: combination of both thresholding in one matrix\n",
    "\"\"\"\n",
    "def threshold_image(img):\n",
    "    img = np.copy(img)\n",
    "\n",
    "#     yellow and white binary\n",
    "    _, wy_binary = select_white_yellow(img)\n",
    "\n",
    "    # x gradient binary\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    sx_thresh=(40, 150)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # combining both\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, wy_binary))\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(wy_binary == 1) | (sxbinary == 1)] = 1\n",
    "#     return select_white_yellow(img)\n",
    "    return color_binary, combined_binary\n",
    "\n",
    "\"\"\"\n",
    "helper function to test thresholding\n",
    "\"\"\"\n",
    "def test_threshold(images):\n",
    "    for i, fname in enumerate(images):\n",
    "        image = mpimg.imread(fname)\n",
    "#         color_binary, combined_binary = threshold_image(image, s_thresh=(175, 250), sx_thresh=(30, 150))\n",
    "        color_binary, combined_binary = threshold_image(image)\n",
    "\n",
    "        # Plot the result\n",
    "        f, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "        f.tight_layout()\n",
    "\n",
    "#         ax1.imshow(color_binary)\n",
    "#         ax1.set_title('Color(blue) and Gradient(green) Image', fontsize=40)\n",
    "\n",
    "        ax.imshow(combined_binary)\n",
    "        ax.set_title('Color and Gradient Threshold Result', fontsize=40)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.savefig('./output_images/test_threshold%s.jpg'%str(i))\n",
    "\n",
    "test_threshold(glob.glob('./test_images/test*.jpg') + glob.glob('/test_images/straight_lines*.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to provide calibration of perspective transform matrix M.\n",
    "input\n",
    "img: the image matrix for calibration, should be a straight road images\n",
    "output\n",
    "warped: the result of the perspective transformed images\n",
    "M: perspective transform matrix M\n",
    "src, dst: the coordinate of the polygon corners in source and destination images respectively\n",
    "\"\"\"\n",
    "def calibrate_perspective(img, objpoints, imgpoints):\n",
    "    # first undistort the image by using existing calibration before\n",
    "    undist = cal_undistort(img, objpoints, imgpoints)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # For source points I'm grabbing the outer four detected corners\n",
    "    src = np.float32([[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],\n",
    "                     [((img_size[0] / 6) - 10), img_size[1]],\n",
    "                     [(img_size[0] * 5 / 6) + 45, img_size[1]],\n",
    "                     [(img_size[0] / 2 + 60), img_size[1] / 2 + 100]])\n",
    "    dst = np.float32([[(img_size[0] / 4), 0],\n",
    "                     [(img_size[0] / 4), img_size[1]],\n",
    "                     [(img_size[0] * 3 / 4), img_size[1]],\n",
    "                     [(img_size[0] * 3 / 4), 0]])\n",
    "\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(undist, M, img_size) \n",
    "    return warped, M, Minv, src, dst\n",
    "\n",
    "def test_calibrate_perspective(images, objpoints, imgpoints):\n",
    "    for i, fname in enumerate(images):\n",
    "        img = mpimg.imread(fname)\n",
    "        top_down, perspective_M, perspective_Minv, src, dst = calibrate_perspective(img, objpoints, imgpoints)\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(img)\n",
    "        ax1.plot(list(src.T[0]) + [src.T[0][0]], list(src.T[1]) + [src.T[1][0]], c='r', linewidth=3.0)\n",
    "        ax1.set_title('Original Image', fontsize=50)\n",
    "        ax2.imshow(top_down)\n",
    "        ax2.plot(list(dst.T[0]) + [dst.T[0][0]], list(dst.T[1]) + [dst.T[1][0]], c='r', linewidth=3.0)\n",
    "        ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.savefig('./output_images/test_calibrate_perspective%s.jpg'%(str(i)))\n",
    "\n",
    "test_calibrate_perspective(glob.glob('./test_images/straight_lines*.jpg'), objpoints, imgpoints)\n",
    "_, perspective_M, perspective_Minv, _, _ = calibrate_perspective(\n",
    "                                            mpimg.imread('./test_images/straight_lines1.jpg'),\n",
    "                                            objpoints, imgpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transform using calibrated matrix M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to perform top-down perspective transform using matrix M\n",
    "input:\n",
    "self explanatory\n",
    "output\n",
    "color_img: original thresholded color image\n",
    "warped: transformed image\n",
    "\"\"\"\n",
    "def perspective_transform(img, M, objpoints, imgpoints):\n",
    "    color_img, img = threshold_image(img)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    undist = cal_undistort(img, objpoints, imgpoints)\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    return color_img, warped\n",
    "\n",
    "\"\"\"\n",
    "helper function to test perspective transform\n",
    "\"\"\"\n",
    "def test_perspective_transform(images, M):\n",
    "    for i, fname in enumerate(images):\n",
    "        img = mpimg.imread(fname)\n",
    "        color_img, warped = perspective_transform(img, M, objpoints, imgpoints)\n",
    "        \n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(color_img * 255)\n",
    "        ax1.set_title('Original thresholded Image', fontsize=50)\n",
    "        ax2.imshow(warped, cmap='binary')\n",
    "        ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.savefig('./output_images/test_perspective_transform%s.jpg'%(str(i)))\n",
    "\n",
    "test_perspective_transform(glob.glob('./test_images/test*.jpg'), perspective_M)\n",
    "binary_warpeds = []\n",
    "for i, fname in enumerate(glob.glob('./test_images/test*.jpg')):\n",
    "    _, warped = perspective_transform(mpimg.imread(fname), perspective_M, objpoints, imgpoints)\n",
    "    binary_warpeds.append(warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to obtain radius of curvature from the given points, converted to meters.\n",
    "input\n",
    "x, y: position (x,y) of nonzero pixels in the image\n",
    "y_eval: roc at the position we want to evaluate, \n",
    "    usually its nearest to the car (bottom of the image) e.g. 719 for image of height 720.\n",
    "output\n",
    "roc: radius of curvature in meters\n",
    "\"\"\"\n",
    "YM_PER_PIX = 30/720 # meters per pixel in y dimension\n",
    "XM_PER_PIX = 3.7/700 # meters per pixel in x dimension\n",
    "def get_radius(x, y, y_eval):\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(y*YM_PER_PIX, x*XM_PER_PIX, 2)\n",
    "    right_fit_cr = np.polyfit(y*YM_PER_PIX, x*XM_PER_PIX, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    roc = ((1 + (2*left_fit_cr[0]*y_eval*YM_PER_PIX + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    return roc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to find the lane using sliding window\n",
    "input\n",
    "binary_warped: binary images from top down perspective\n",
    "output\n",
    "left_fit, right_fit: the fitted parameters of left and right lane\n",
    "out_img: output image of the fitted function\n",
    "left_curverad, right_curverad: roc of left and right lanes\n",
    "\"\"\"\n",
    "def fit_first_binary_warped(binary_warped, plot=True):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,0:1200], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    offset = 100\n",
    "    leftx_base = np.argmax(histogram[offset:midpoint]) + offset\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 10\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_curverad = (get_radius(leftx, lefty, np.max(ploty)))\n",
    "    right_curverad = (get_radius(rightx, righty, np.max(ploty)))\n",
    "\n",
    "    def test_fit_first_binary_warped():\n",
    "        # Generate x and y values for plotting\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        plt.imshow(out_img)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        plt.savefig('./output_images/test_fit_first.jpg')\n",
    "    \n",
    "    if plot:\n",
    "        test_fit_first_binary_warped()\n",
    "        \n",
    "    return left_fit, right_fit, out_img, left_curverad, right_curverad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_fit, right_fit, _, left_curverad, right_curverad = fit_first_binary_warped(binary_warpeds[0])\n",
    "\n",
    "print(left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to fit next binary warped using the previously know left_fit and right_fit\n",
    "\"\"\"\n",
    "def fit_next_binary_warped(binary_warped, left_fit, right_fit, plot=False, idx_file=0):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    if plot:\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        f, _ = plt.subplots(1, 1, figsize=(12, 4))\n",
    "        plt.imshow(result)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        plt.savefig('./output_images/test_next_fit%s.jpg'%str(idx_file))\n",
    "    \n",
    "    # find radius of curvature\n",
    "    left_curverad = (get_radius(leftx, lefty, np.max(ploty)))\n",
    "    right_curverad = (get_radius(rightx, righty, np.max(ploty)))\n",
    "    \n",
    "    return left_fit, right_fit, out_img, left_fitx, right_fitx, ploty, left_curverad, right_curverad\n",
    "\n",
    "for i, binary_warped in enumerate(binary_warpeds):\n",
    "    left_fit, right_fit, _, left_fitx, right_fitx, ploty, left_curverad, right_curverad = \\\n",
    "        fit_next_binary_warped(binary_warped, left_fit, right_fit, plot=True, idx_file=i)\n",
    "    print(left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Project back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to obtain offset of the center of the car to the center of the lane\n",
    "input:\n",
    "binary image, warped back to the original camera view, with known position of the lane\n",
    "output:\n",
    "the offset value, positive numbers mean the car is slightly on the right of the lane center, otherwise is true.\n",
    "\"\"\"\n",
    "def get_center_offset(newwarp):\n",
    "    xmax = newwarp.shape[1]\n",
    "    return 0.5 *(xmax - (xmax - np.argmax(np.flipud(newwarp[-1,:,1])) \n",
    "                         + np.argmax(newwarp[-1,:,1])) ) * XM_PER_PIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to project back the lane fitting into the original image.\n",
    "input\n",
    "image: input image matrix\n",
    "M, Minv: perspective matrices (and its inverse)\n",
    "objpoints, imgpoints: points in 3D world space and 2D image space (from camera distortion calibration)\n",
    "left_fit, right_fit: initial quadratic fitting parameters for lane finding\n",
    "output\n",
    "result: the resulting images with fitted lane onto the original image\n",
    "left_curverad, right_curverad: roc of left and right lane \n",
    "lane_center: car-to-lane offset distance \n",
    "left_fit, right_fit: the new quadratic fitting parameters (for input of next frame)\n",
    "\"\"\"\n",
    "def project_back(image, M, Minv, objpoints, imgpoints, left_fit, right_fit, idx_plot=0, plot=True):\n",
    "    _, warped = perspective_transform(image, M, objpoints, imgpoints)\n",
    "    undist = cal_undistort(image, objpoints, imgpoints)\n",
    "    left_fit, right_fit, _, left_fitx, right_fitx, ploty, left_curverad, right_curverad = \\\n",
    "        fit_next_binary_warped(warped, left_fit, right_fit, plot=False)\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    # find the lane center\n",
    "    lane_center = get_center_offset(newwarp)  \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    # add the radius and offset info on the image\n",
    "    cv2.putText(result, 'Vehicle is %.2f m from the center' \n",
    "                        %(lane_center),\n",
    "                        (40, 100), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2)\n",
    "    cv2.putText(result, 'ROC left=%.0f m,right=%.0f m' \n",
    "                        %(left_curverad, right_curverad),\n",
    "                        (40, 200), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2)\n",
    "    if plot:\n",
    "        f, _ = plt.subplots(1,1, figsize=(12.8, 7.2))\n",
    "        plt.imshow(result)\n",
    "        plt.savefig('./output_images/test_project_back%s.jpg'%str(idx_plot))\n",
    "    return result, left_curverad, right_curverad, lane_center, left_fit, right_fit\n",
    "\n",
    "for i, fname in enumerate(glob.glob('./test_images/test*.jpg')):\n",
    "    result, left_curverad, right_curverad, lane_center, left_fit, right_fit = \\\n",
    "        project_back(mpimg.imread(fname), perspective_M, perspective_Minv, \n",
    "                     objpoints, imgpoints, left_fit, right_fit, idx_plot=i)\n",
    "    print(left_curverad, right_curverad, lane_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Video pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to create a pipeline for the video, we will save all the calibration tools we needed so far\n",
    "calibration = {'M': perspective_M, 'Minv': perspective_Minv,\n",
    "               'objpoints': objpoints, 'imgpoints': imgpoints}\n",
    "pickle.dump(calibration, open('calibration.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an object to keep track of the pipeline progress\n",
    "class Pipeline():\n",
    "    def __init__(self):\n",
    "        calibration = pickle.load(open('calibration.pickle', 'rb'))\n",
    "        self.M = calibration['M']\n",
    "        self.Minv = calibration['Minv']\n",
    "        self.objpoints = calibration['objpoints']\n",
    "        self.imgpoints = calibration['imgpoints']\n",
    "        \n",
    "        # keep track of two results\n",
    "        self.left_roc = []\n",
    "        self.right_roc = []\n",
    "        self.line_base_pos = []\n",
    "        \n",
    "        # keep state of previous frames to help with the next frame\n",
    "        self.detected = False\n",
    "        self.left_fit = None\n",
    "        self.right_fit = None\n",
    "        \n",
    "    def process_image(self, image):\n",
    "        if not self.detected: # if previous frame detection does not exist \n",
    "            _, warped = perspective_transform(image, self.M, self.objpoints, self.imgpoints)\n",
    "            left_fit, right_fit, _, _, _ = fit_first_binary_warped(warped, plot=False)\n",
    "            result, left_curverad, right_curverad, lane_center, left_fit, right_fit = \\\n",
    "                project_back(image, self.M, self.Minv, \n",
    "                             self.objpoints, self.imgpoints, \n",
    "                             left_fit, right_fit, plot=False)\n",
    "            self.detected = True\n",
    "        else:\n",
    "            result, left_curverad, right_curverad, lane_center, left_fit, right_fit = \\\n",
    "                project_back(image, self.M, self.Minv, \n",
    "                             self.objpoints, self.imgpoints, \n",
    "                             self.left_fit, self.right_fit, plot=False)\n",
    "        self.left_fit, self.right_fit = left_fit, right_fit\n",
    "        self.left_roc.append(left_curverad)\n",
    "        self.right_roc.append(right_curverad)\n",
    "        self.line_base_pos.append(lane_center)\n",
    "        return result\n",
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_output = './output_videos/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline.process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"480\" height=\"270\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Additional Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot ROC and center offset\n",
    "x = range(len(pipeline.left_roc))\n",
    "f, _ = plt.subplots(1, 1, figsize=(10, 5))\n",
    "plt.scatter(x, pipeline.left_roc, color='blue')\n",
    "plt.scatter(x, pipeline.right_roc, color='red')\n",
    "plt.title('Radius of curvature of left (blue) and right (red) lanes')\n",
    "# plt.plot(x, pipeline.line_base_pos, color='blue')\n",
    "plt.ylim(0, 5000)\n",
    "plt.savefig('./output_images/project_video_roc.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot ROC and center offset\n",
    "x = range(len(pipeline.left_roc))\n",
    "f, _ = plt.subplots(1, 1, figsize=(10, 5))\n",
    "plt.title('Car position offset from the lane')\n",
    "plt.scatter(x, pipeline.line_base_pos, color='blue')\n",
    "plt.ylim(-1, 1)\n",
    "plt.savefig('./output_images/project_video_center.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
